{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIqIcmtwLG7rnbYe4ki/Px",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charan01729/-Movie-Recommendation-System-Using-Content-Based-Filtering/blob/main/Movie_Recommendation_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "982716ff"
      },
      "source": [
        "# Movie Recommendation System Using Content-Based Filtering\n",
        "\n",
        "**Technologies used**: Python, Pandas, Scikit-Learn.\n",
        "\n",
        "*   Built a content-based recommendation model using vectorization and cosine similarity, achieving Precision@5: 0.9154, Recall@5: 0.0027, MAP@5: 0.8890, and NDCG@5: 0.9185 on a sample.\n",
        "*   Analyzed movie metadata (genres, cast, keywords) to generate personalized recommendations.\n",
        "*   Enabled users to discover similar movies based on selected input titles using text-based similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRlQi6oPTztV",
        "outputId": "302c3e88-f22c-4a4e-a268-016810b10df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 - imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import time\n",
        "import tracemalloc\n",
        "from difflib import get_close_matches\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pickle"
      ],
      "metadata": {
        "id": "zSgsGasvW4JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qq1lsAgJUPYx",
        "outputId": "219556b0-a8de-4013-bd48-5468e55f77b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b150434a-c8d7-4f4b-940c-7ccd21a56d02\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b150434a-c8d7-4f4b-940c-7ccd21a56d02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tmdb_5000_credits.csv to tmdb_5000_credits.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lbysw_iCX6Wk",
        "outputId": "46a4a699-7701-4ca9-9c3a-df616bdde992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2dd9b5f-9e77-4b2f-b615-885540930356\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2dd9b5f-9e77-4b2f-b615-885540930356\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tmdb_5000_movies.csv to tmdb_5000_movies.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - load files (assumes tmdb_5000_movies.csv and tmdb_5000_credits.csv are in working dir)\n",
        "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
        "\n",
        "# merge on title (like your original)\n",
        "movies = movies.merge(credits, on='title')\n",
        "\n",
        "# unify id column name (some files use 'id' others 'movie_id')\n",
        "if 'movie_id' not in movies.columns and 'id' in movies.columns:\n",
        "    movies = movies.rename(columns={'id':'movie_id'})\n",
        "\n",
        "# select only relevant columns\n",
        "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
        "\n",
        "# drop rows with missing values in these columns\n",
        "movies.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "aVofKlVZW_kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - parsing helpers and building tags\n",
        "def safe_literal_eval(x):\n",
        "    try:\n",
        "        return ast.literal_eval(x)\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def get_names(text):\n",
        "    L = safe_literal_eval(text)\n",
        "    return [d.get('name') for d in L if isinstance(d, dict) and d.get('name')]\n",
        "\n",
        "def get_director(text):\n",
        "    L = safe_literal_eval(text)\n",
        "    return [d.get('name') for d in L if isinstance(d, dict) and d.get('job') == 'Director']\n",
        "\n",
        "def collapse_no_space(list_in):\n",
        "    return [str(x).replace(' ', '') for x in list_in]\n",
        "\n",
        "# apply conversions\n",
        "movies['genres']   = movies['genres'].apply(get_names).apply(lambda x: x)      # keep all genres\n",
        "movies['keywords'] = movies['keywords'].apply(get_names)\n",
        "movies['cast']     = movies['cast'].apply(lambda x: [d.get('name') for d in safe_literal_eval(x)[:3]])\n",
        "movies['crew']     = movies['crew'].apply(get_director)\n",
        "\n",
        "# remove spaces inside tokens (e.g., \"Tom Hanks\" -> \"TomHanks\") to keep tokens single-word\n",
        "for col in ['genres','keywords','cast','crew']:\n",
        "    movies[col] = movies[col].apply(collapse_no_space)\n",
        "\n",
        "# overview -> token list\n",
        "movies['overview'] = movies['overview'].apply(lambda x: str(x).split())\n",
        "\n",
        "# build tags\n",
        "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
        "\n",
        "# final dataframe used for model\n",
        "new = movies[['movie_id','title','tags','genres']].copy()\n",
        "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# reset index so positional indices (0..n-1) match NN indices\n",
        "new = new.reset_index(drop=True)\n",
        "\n",
        "# quick check\n",
        "print(\"Dataset size:\", len(new))\n",
        "print(new[['title','tags']].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I773onAOYcWP",
        "outputId": "c4fa4b36-d432-4f73-eab4-b451745bae94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 4806\n",
            "                                      title  \\\n",
            "0                                    Avatar   \n",
            "1  Pirates of the Caribbean: At World's End   \n",
            "2                                   Spectre   \n",
            "\n",
            "                                                tags  \n",
            "0  In the 22nd century, a paraplegic Marine is di...  \n",
            "1  Captain Barbossa, long believed to be dead, ha...  \n",
            "2  A cryptic message from Bondâ€™s past sends him o...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - vectorize (sparse) and build NN index\n",
        "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
        "vector = cv.fit_transform(new['tags'])         # sparse matrix (n_samples x n_features)\n",
        "\n",
        "# NearestNeighbors with cosine distance (we'll ask for n_neighbors = k+1)\n",
        "nn = NearestNeighbors(n_neighbors=11, metric='cosine', algorithm='brute')\n",
        "nn.fit(vector)\n",
        "\n",
        "# precompute neighbors for all items (fast lookup at query time)\n",
        "distances, indices = nn.kneighbors(vector)    # distances shape (n_samples, 11), indices likewise\n",
        "\n",
        "print(\"Vector shape:\", vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89F1X0zuYn4s",
        "outputId": "d6776775-2863-46f0-fde5-7c36898b4dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector shape: (4806, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - recommend + fuzzy title match (uses difflib.get_close_matches)\n",
        "titles = new['title'].tolist()\n",
        "\n",
        "def find_title(query):\n",
        "    if query in titles:\n",
        "        return query\n",
        "    # fuzzy suggestions\n",
        "    suggestions = get_close_matches(query, titles, n=5, cutoff=0.4)\n",
        "    if suggestions:\n",
        "        print(\"No exact match. Closest matches found (using fuzzy matching):\")\n",
        "        for i, s in enumerate(suggestions, 1):\n",
        "            print(f\"{i}. {s}\")\n",
        "        print(\"Using the first suggestion:\", suggestions[0])\n",
        "        return suggestions[0]\n",
        "    return None\n",
        "\n",
        "def recommend(movie_query, k=5):\n",
        "    title = find_title(movie_query)\n",
        "    if title is None:\n",
        "        return [\"Movie not found in dataset (and no close match)\"]\n",
        "    idx = new.index[new['title'] == title][0]    # integer positional index\n",
        "    rec_pos = indices[idx, 1:k+1]                # skip self (position 0)\n",
        "    return new.iloc[rec_pos]['title'].tolist()"
      ],
      "metadata": {
        "id": "K1z3mdhVYsqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 - interactive user input\n",
        "movie_name = input(\"Enter movie name: \").strip()\n",
        "k = input(\"How many recommendations? (enter integer, default 5): \").strip()\n",
        "k = int(k) if k.isdigit() else 5\n",
        "\n",
        "recs = recommend(movie_name, k=k)\n",
        "print(f\"\\nTop {k} recommendations for '{movie_name}':\")\n",
        "for i, r in enumerate(recs, 1):\n",
        "    print(f\"{i}. {r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIIlOOvgYvaD",
        "outputId": "c8008d42-a752-4f07-de4e-e6c648220761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter movie name: Gandhi\n",
            "How many recommendations? (enter integer, default 5): 5\n",
            "\n",
            "Top 5 recommendations for 'Gandhi':\n",
            "1. Gandhi, My Father\n",
            "2. The Wind That Shakes the Barley\n",
            "3. A Passage to India\n",
            "4. Guiana 1838\n",
            "5. Ramanujan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 - metrics\n",
        "import math\n",
        "\n",
        "def precision_at_k(predicted, actual, k):\n",
        "    if k == 0: return 0.0\n",
        "    return len(set(predicted[:k]) & set(actual)) / k\n",
        "\n",
        "def recall_at_k(predicted, actual, k):\n",
        "    if not actual: return 0.0\n",
        "    return len(set(predicted[:k]) & set(actual)) / len(actual)\n",
        "\n",
        "def apk(predicted, actual, k):\n",
        "    if not actual: return 0.0\n",
        "    score = 0.0\n",
        "    hits = 0\n",
        "    for i, p in enumerate(predicted[:k], start=1):\n",
        "        if p in actual and p not in predicted[:i-1]:\n",
        "            hits += 1\n",
        "            score += hits / i\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "def ndcg_at_k(predicted, actual, k):\n",
        "    dcg = 0.0\n",
        "    for i, p in enumerate(predicted[:k], start=1):\n",
        "        if p in actual:\n",
        "            dcg += 1.0 / math.log2(i + 1)\n",
        "    idcg = sum(1.0 / math.log2(i + 1) for i in range(1, min(len(actual), k) + 1))\n",
        "    return dcg / idcg if idcg > 0 else 0.0"
      ],
      "metadata": {
        "id": "2qIfRHKDY2_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 - evaluate on a sample (genre-overlap as proxy relevance)\n",
        "def evaluate_recommender(k=5, sample_size=500):\n",
        "    n = len(new)\n",
        "    sample = new.sample(n=min(sample_size, n), random_state=42).reset_index(drop=True)\n",
        "\n",
        "    precisions, recalls, maps, ndcgs = [], [], [], []\n",
        "\n",
        "    for idx_row in range(len(sample)):\n",
        "        # find positional index in full 'new' dataframe\n",
        "        row_title = sample.loc[idx_row, 'title']\n",
        "        full_idx = new.index[new['title'] == row_title][0]\n",
        "\n",
        "        # ground truth = titles that share at least one genre (exclude self)\n",
        "        query_genres = set(new.iloc[full_idx]['genres'])\n",
        "        if len(query_genres) == 0:\n",
        "            continue\n",
        "        actual_idxs = [i for i in range(len(new)) if i != full_idx and len(set(new.iloc[i]['genres']) & query_genres) > 0]\n",
        "        actual_titles = new.iloc[actual_idxs]['title'].tolist()\n",
        "\n",
        "        # predicted using precomputed indices\n",
        "        pred_idxs = indices[full_idx, 1:k+1]\n",
        "        predicted_titles = new.iloc[pred_idxs]['title'].tolist()\n",
        "\n",
        "        precisions.append(precision_at_k(predicted_titles, actual_titles, k))\n",
        "        recalls.append(recall_at_k(predicted_titles, actual_titles, k))\n",
        "        maps.append(apk(predicted_titles, actual_titles, k))\n",
        "        ndcgs.append(ndcg_at_k(predicted_titles, actual_titles, k))\n",
        "\n",
        "    print(f\"Evaluated on {len(precisions)} queries (sample_size={len(sample)})\")\n",
        "    print(f\"Precision@{k}: {np.mean(precisions):.4f}\")\n",
        "    print(f\"Recall@{k}:    {np.mean(recalls):.4f}\")\n",
        "    print(f\"MAP@{k}:       {np.mean(maps):.4f}\")\n",
        "    print(f\"NDCG@{k}:      {np.mean(ndcgs):.4f}\")\n",
        "\n",
        "# run evaluation (example)\n",
        "evaluate_recommender(k=5, sample_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFtpS0lGY79W",
        "outputId": "8ffb2877-72b1-40e9-eed6-3629934fa8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 499 queries (sample_size=500)\n",
            "Precision@5: 0.9154\n",
            "Recall@5:    0.0027\n",
            "MAP@5:       0.8890\n",
            "NDCG@5:      0.9185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 - save model artifacts and quick latency check\n",
        "pickle.dump(cv, open('cv_countvec.pkl', 'wb'))\n",
        "pickle.dump((indices, distances), open('knn_indices_distances.pkl', 'wb'))\n",
        "pickle.dump(new, open('movie_list_df.pkl', 'wb'))\n",
        "\n",
        "# measure latency for one query (transform + kneighbors)\n",
        "query_title = new.iloc[0]['title']\n",
        "start = time.time()\n",
        "qvec = cv.transform([new.iloc[0]['tags']])\n",
        "d, idxs = nn.kneighbors(qvec, n_neighbors=11)\n",
        "latency = time.time() - start\n",
        "print(\"Sample query:\", query_title)\n",
        "print(\"Latency (transform + knn): {:.4f} sec\".format(latency))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWf5m4NeZzB-",
        "outputId": "1303e10e-2188-4995-c203-f5b600540a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample query: Avatar\n",
            "Latency (transform + knn): 0.0118 sec\n"
          ]
        }
      ]
    }
  ]
}